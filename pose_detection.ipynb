{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import math\n",
    "import cv2\n",
    "import pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the mediapipe model\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.3)\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectPose(image, pose, display=True):\n",
    "    \"\"\"Places landmarks on an image.\"\"\"\n",
    "    output_image = image.copy()\n",
    "    \n",
    "    # Identify all landmarks\n",
    "    imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(imageRGB)\n",
    "    \n",
    "    # Retrieve the height and width of the input image.\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    # Append all landmarks and draw them on the OUTPUT image\n",
    "    landmarks = []\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(image=output_image, landmark_list=results.pose_landmarks,\n",
    "                                  connections=mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            landmarks.append((int(landmark.x * width), int(landmark.y * height),\n",
    "                                  (landmark.z * width)))\n",
    "    \n",
    "    return output_image, landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAngle(landmark1, landmark2, landmark3):\n",
    "    \"\"\"Calculate the angle between 3 landmarks.\"\"\"\n",
    "    # Get the required landmarks coordinates.\n",
    "    x1, y1, _ = landmark1\n",
    "    x2, y2, _ = landmark2\n",
    "    x3, y3, _ = landmark3\n",
    " \n",
    "    # Calculate the angle between the three points\n",
    "    angle = math.degrees(math.atan2(y3 - y2, x3 - x2) - math.atan2(y1 - y2, x1 - x2))\n",
    "    \n",
    "    # Make the angle positive (FOR NOW)\n",
    "    if angle < 0:\n",
    "        angle += 360\n",
    "\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_salute(shoulder, elbow, wrist, frame):\n",
    "    \"\"\"Checks to see if the person is saluting.\"\"\"\n",
    "    is_saluting = True if 35 < calculateAngle(shoulder, elbow, wrist) < 50 else False\n",
    "    if is_saluting:\n",
    "        cv2.putText(frame, \"Saluting!\", (10, 30), cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 2)\n",
    "    else:\n",
    "        cv2.putText(frame, \"nope\", (10, 30), cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 2)\n",
    "    return is_saluting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_forward():\n",
    "    \"\"\"Press the w key on the user's laptop.\"\"\"\n",
    "    pyautogui.keyDown('W')\n",
    "    pyautogui.keyUp('W')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_video = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, model_complexity=1)\n",
    " \n",
    "# Initialize the VideoCapture object to read from the webcam.\n",
    "video = cv2.VideoCapture(0)\n",
    "cv2.namedWindow('Pose Detection', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Initialize a variable to store the time of the previous frame.\n",
    "time1 = 0\n",
    " \n",
    "# Iterate until the video is accessed successfully.\n",
    "while video.isOpened():\n",
    "    \n",
    "    # Read a frame.\n",
    "    ok, frame = video.read()\n",
    "    \n",
    "    # Check if frame is not read properly.\n",
    "    if not ok:\n",
    "        break\n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # Adjust the frame\n",
    "    frame_height, frame_width, _ =  frame.shape\n",
    "    frame = cv2.resize(frame, (int(frame_width * (640 / frame_height)), 640))\n",
    "    \n",
    "    # Perform Pose landmark detection.\n",
    "    frame, landmarks = detectPose(frame, pose_video, display=False)\n",
    "\n",
    "    if landmarks:\n",
    "        is_saluting = check_salute(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value], landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value], landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value], frame)\n",
    "        if is_saluting:\n",
    "            move_forward()\n",
    "    \n",
    "    # Display the frame.\n",
    "    cv2.imshow('Pose Detection', frame)\n",
    "    \n",
    "    # Check to see if the user pressed 'esc'\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if(k == 27):\n",
    "        break\n",
    " \n",
    "# Clean Up\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
